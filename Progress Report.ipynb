{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Capston Project | Yelp - Progress Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic informatio on the dataset: \n",
    "- 2.2M reviews and 591K tips by 552K users for 77K businesses\n",
    "- 566K business attributes, e.g., hours, parking availability, ambience.\n",
    "- Social network of 552K users for a total of 3.5M social edges.\n",
    "- Aggregated check-ins over time for each of the 77K businesses\n",
    "- 200,000 pictures from the included businesses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5 files: businesss(77,445 rows), checkin(55,569 rows), review(2,225,213 rows), tip(591,864 rows), user(552,339 rows) \n",
    "- Business has a total of 36 attributes.\n",
    "- (u'Accepts Credit Cards', 56528),\n",
    " (u'Price Range', 50070),\n",
    " (u'Parking', 44617),\n",
    " (u'Good for Kids', 30328),\n",
    " (u'Outdoor Seating', 26601),\n",
    " (u'Good For Groups', 26011),\n",
    " (u'Delivery', 23624),\n",
    " (u'Take-out', 23601),\n",
    " (u'Attire', 23487),\n",
    " (u'Alcohol', 23328),\n",
    " (u'Takes Reservations', 23072),\n",
    " (u'Has TV', 22703),\n",
    " (u'Wheelchair Accessible', 22511),\n",
    " (u'Good For', 22080),\n",
    " (u'Wi-Fi', 21624),\n",
    " (u'Ambience', 21447),\n",
    " (u'Waiter Service', 21332),\n",
    " (u'Noise Level', 21305),\n",
    "- The missing attributes are either filled with 'unknown' or False based on what attribute it is. For example, attributes such as 'delivery', 'cater', 'take out', 'Wheelchair Accessible', 'Dogs Allowed' and 'Happy Hour' are more likely to be the determining factors of whether someone decides to visit that certain business, therefore the missing values are filled with 'False.'  Assuming some who has a dog with him/her yelping 'cafe' nearby,  that person is more likely to treat the missing 'Dog Allowed' information as if dogs are not allowed and find a place that he/she is sure that they can visit with dogs. However,  none-determining factors such as 'Coat Check' and 'Has TV', as well as factors we cannot assume like 'Noise Level', 'Price Range', and 'Takes Reservations' are filled with 'unknown.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cultural Trends: \n",
    "By adding a diverse set of cities, we want participants to compare and contrast what makes a particular city different. For example, are people in international cities less concerned about driving in to a business, indicated by their lack of mention about parking? What cuisines are Yelpers raving about in these different countries? Do Americans tend to eat out late compared to the Germans and English? In which countries are Yelpers sticklers for service quality? In international cities such as Montreal, are French speakers reviewing places differently than English speakers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "By adding a diverse set of cities, we want participants to compare and contrast what makes a particular city different. For example, are people in international cities less concerned about driving in to a business, indicated by their lack of mention about parking? What cuisines are Yelpers raving about in these different countries? Do Americans tend to eat out late compared to the Germans and English? In which countries are Yelpers sticklers for service quality? In international cities such as Montreal, are French speakers reviewing places differently than English speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../capstone/merged_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop = ['votes_y','friends','elite','compliments','votes_x','type_y','user_id','type_x','review_id','attributes',\\\n",
    "        'business_id','full_address','hours','neighborhoods','open','Unnamed: 0','city','name_x','name_y','type','compliment']\n",
    "ndf = df.drop(drop, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = ['state', 'credit_card', 'price', 'parking', 'kids', 'ourdoor_seating', 'groups',\\\n",
    "    'delivery', 'take_out', 'attire', 'alcohol', 'reservation', 'tv', 'wheelchair', 'wifi', 'waiter', \\\n",
    "     'noise', 'cater', 'appointment_only', 'happy_hour', 'dancing', 'coatcheck', 'dogs', 'drive_thru']\n",
    "temp = pd.DataFrame()\n",
    "for i in c:\n",
    "    print i\n",
    "    unique = list(ndf[i].unique())\n",
    "    unique_n = {y:x for x, y in enumerate(unique)}\n",
    "    temp[i] = ndf[i].apply(lambda x: unique_n[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = temp.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = temp['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy Score: 0.48843537415\n",
      "Bagging Decision Tree Accuracy Score: 0.499319727891\n",
      "Random Forest Accuracy Score: 0.478911564626\n",
      "Extra Tree Accuracy Score: 0.503401360544\n",
      "Ada Boost Accuracy Score: 0.102040816327\n",
      "Gradient Boosting Accuracy Score: 0.500680272109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,RandomForestClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# try other ensemble methods (random forest=, extra tree, adaboost, gradient boosting)\n",
    "dt = DecisionTreeClassifier(random_state=3)\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier(random_state=3))\n",
    "rfdt = RandomForestClassifier(random_state=3)\n",
    "etdt = ExtraTreesClassifier(random_state=3)\n",
    "abdt = AdaBoostClassifier(random_state=3)\n",
    "gbdt = GradientBoostingClassifier(random_state=3)\n",
    "\n",
    "# apply those models to the train set \n",
    "result_dt = dt.fit(x_train,y_train)\n",
    "result_bdt = bdt.fit(x_train,y_train)\n",
    "result_rfdt = rfdt.fit(x_train,y_train)\n",
    "result_etdt = etdt.fit(x_train,y_train)\n",
    "result_abdt = abdt.fit(x_train,y_train)\n",
    "result_gbdt = gbdt.fit(x_train,y_train)\n",
    "\n",
    "# print out the accuracy scores \n",
    "print \"Decision Tree Accuracy Score: \" + str(result_dt.score(x_test,y_test))\n",
    "print \"Bagging Decision Tree Accuracy Score: \" + str(result_bdt.score(x_test,y_test))\n",
    "print \"Random Forest Accuracy Score: \" + str(result_rfdt.score(x_test,y_test))\n",
    "print \"Extra Tree Accuracy Score: \" + str(result_etdt.score(x_test,y_test))\n",
    "print \"Ada Boost Accuracy Score: \" + str(result_abdt.score(x_test,y_test))\n",
    "print \"Gradient Boosting Accuracy Score: \" + str(result_gbdt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "                  importance\n",
      "wifi                0.110719\n",
      "price               0.094095\n",
      "alcohol             0.079364\n",
      "ourdoor_seating     0.069529\n",
      "tv                  0.066923\n",
      "noise               0.062370\n",
      "wheelchair          0.057440\n",
      "reservation         0.056857\n",
      "cater               0.055550\n",
      "waiter              0.046633\n",
      "kids                0.045608\n",
      "parking             0.041969\n",
      "delivery            0.031881\n",
      "groups              0.025191\n",
      "coatcheck           0.024479\n",
      "dogs                0.024330\n",
      "happy_hour          0.022103\n",
      "credit_card         0.020734\n",
      "take_out            0.019872\n",
      "attire              0.019321\n",
      "appointment_only    0.009646\n",
      "dancing             0.008333\n",
      "drive_thru          0.007052\n",
      "\n",
      "Extra Tree\n",
      "                  importance\n",
      "wifi                0.114921\n",
      "price               0.079831\n",
      "alcohol             0.078879\n",
      "noise               0.072864\n",
      "ourdoor_seating     0.069988\n",
      "tv                  0.063693\n",
      "wheelchair          0.054021\n",
      "kids                0.048472\n",
      "parking             0.048362\n",
      "reservation         0.048243\n",
      "cater               0.045834\n",
      "waiter              0.037512\n",
      "delivery            0.030905\n",
      "coatcheck           0.029581\n",
      "groups              0.029097\n",
      "happy_hour          0.028996\n",
      "dogs                0.024383\n",
      "take_out            0.024293\n",
      "credit_card         0.021613\n",
      "attire              0.020485\n",
      "dancing             0.011558\n",
      "appointment_only    0.008553\n",
      "drive_thru          0.007914\n",
      "\n",
      "Gradient Boosting\n",
      "                  importance\n",
      "parking             0.086447\n",
      "tv                  0.072042\n",
      "alcohol             0.067728\n",
      "ourdoor_seating     0.062705\n",
      "noise               0.061974\n",
      "take_out            0.058970\n",
      "price               0.056800\n",
      "wifi                0.056406\n",
      "reservation         0.052245\n",
      "wheelchair          0.050129\n",
      "waiter              0.044106\n",
      "credit_card         0.039058\n",
      "cater               0.038758\n",
      "groups              0.038451\n",
      "kids                0.037183\n",
      "coatcheck           0.033768\n",
      "delivery            0.029387\n",
      "attire              0.025600\n",
      "happy_hour          0.017438\n",
      "dogs                0.013929\n",
      "dancing             0.008692\n",
      "drive_thru          0.006404\n",
      "appointment_only    0.005117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_importances_rf = pd.DataFrame(result_rfdt.feature_importances_, \n",
    "                                   index = x.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Random Forest'\n",
    "print feature_importances_rf\n",
    "print ''\n",
    "\n",
    "feature_importances_et = pd.DataFrame(result_etdt.feature_importances_, \n",
    "                                   index = x.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Extra Tree'\n",
    "print feature_importances_et\n",
    "print ''\n",
    "\n",
    "feature_importances_ab = pd.DataFrame(result_abdt.feature_importances_, \n",
    "                                   index = x.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Gradient Boosting'\n",
    "print feature_importances_gb\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    try: \n",
    "        z = x.replace('\\n\\n',' ')\n",
    "\n",
    "        return z\n",
    "    except: \n",
    "        pass\n",
    "temp['text']= df['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The skylofts are truly amazing.  We stayed in the two bedroom loft which was about 3000 sq/ft.  There are incredible views of the strip and of the airport.  The rolls royce picked us up at the airport and we bypassed the mile long check in line upon arrival.  We got an escort to the room where the butler was waiting with fresh juice.  All the cokes, fiji water, and sprites included.  The room was incredible.  Completely sound proof and every room and living room has bang and olufson sound systems.  We ordered room service and the butler delivered and set everything up on the dining table.  The food was pricey but very good.  I would highly recommend staying at the skylofts.  You wont regret it!'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.text[595]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# strip unnesscery words\n",
    "stemmer = PorterStemmer()\n",
    "temp['text'] = [stemmer.stem(t.decode('utf-8')) for t in temp['text']]\n",
    "\n",
    "# set stop words and vectorize it \n",
    "cvec = CountVectorizer(stop_words = 'english')\n",
    "cvec.fit(temp['text'])\n",
    "review = pd.DataFrame(cvec.fit_transform(temp['text']).todense(),\n",
    "                       columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = review.values \n",
    "y = temp['state']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy Score: 0.466666666667\n",
      "Bagging Decision Tree Accuracy Score: 0.533333333333\n",
      "Random Forest Accuracy Score: 0.517006802721\n",
      "Extra Tree Accuracy Score: 0.534693877551\n",
      "Ada Boost Accuracy Score: 0.489795918367\n",
      "Gradient Boosting Accuracy Score: 0.563265306122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,RandomForestClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# try other ensemble methods (random forest=, extra tree, adaboost, gradient boosting)\n",
    "dt = DecisionTreeClassifier(random_state=3)\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier(random_state=3))\n",
    "rfdt = RandomForestClassifier(random_state=3)\n",
    "etdt = ExtraTreesClassifier(random_state=3)\n",
    "abdt = AdaBoostClassifier(random_state=3)\n",
    "gbdt = GradientBoostingClassifier(random_state=3)\n",
    "\n",
    "# apply those models to the train set \n",
    "result_dt = dt.fit(x_train,y_train)\n",
    "result_bdt = bdt.fit(x_train,y_train)\n",
    "result_rfdt = rfdt.fit(x_train,y_train)\n",
    "result_etdt = etdt.fit(x_train,y_train)\n",
    "result_abdt = abdt.fit(x_train,y_train)\n",
    "result_gbdt = gbdt.fit(x_train,y_train)\n",
    "\n",
    "# print out the accuracy scores \n",
    "print \"Decision Tree Accuracy Score: \" + str(result_dt.score(x_test,y_test))\n",
    "print \"Bagging Decision Tree Accuracy Score: \" + str(result_bdt.score(x_test,y_test))\n",
    "print \"Random Forest Accuracy Score: \" + str(result_rfdt.score(x_test,y_test))\n",
    "print \"Extra Tree Accuracy Score: \" + str(result_etdt.score(x_test,y_test))\n",
    "print \"Ada Boost Accuracy Score: \" + str(result_abdt.score(x_test,y_test))\n",
    "print \"Gradient Boosting Accuracy Score: \" + str(result_gbdt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "            importance\n",
      "vegas         0.028862\n",
      "charlotte     0.013321\n",
      "strip         0.006695\n",
      "montreal      0.006199\n",
      "pittsburgh    0.005126\n",
      "\n",
      "Extra Tree\n",
      "           importance\n",
      "vegas        0.013041\n",
      "las          0.010051\n",
      "charlotte    0.007318\n",
      "montreal     0.006986\n",
      "phoenix      0.006513\n",
      "\n",
      "Gradient Boosting\n",
      "                 importance\n",
      "parking            0.086447\n",
      "tv                 0.072042\n",
      "alcohol            0.067728\n",
      "ourdoor_seating    0.062705\n",
      "noise              0.061974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_importances_rf = pd.DataFrame(result_rfdt.feature_importances_, \n",
    "                                   index = review.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Random Forest'\n",
    "print feature_importances_rf.head()\n",
    "print ''\n",
    "\n",
    "feature_importances_et = pd.DataFrame(result_etdt.feature_importances_, \n",
    "                                   index = review.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Extra Tree'\n",
    "print feature_importances_et.head()\n",
    "print ''\n",
    "\n",
    "feature_importances_ab = pd.DataFrame(result_abdt.feature_importances_, \n",
    "                                   index = review.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print 'Gradient Boosting'\n",
    "print feature_importances_gb.head()\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Mining and Urban Planning: \n",
    "How much of a business' success is really just location, location, location? Do you see reviewers' behavior change when they travel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Trends: \n",
    "What about seasonal effects: Are HVAC contractors being reviewed just at onset of winter, and manicure salons at onset of summer? Are there more reviews for sports bars on major game days and if so, could you predict that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Categories: \n",
    "Do you see any non-intuitive correlations between business categories e.g., how many karaoke bars also offer Korean food, and vice versa? What businesses deserve their own subcategory (i.e., Szechuan or Hunan versus just \"Chinese restaurants\"), and can you learn this from the review text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP): \n",
    "How well can you guess a review's rating from its text alone? What are the most common positive and negative words used in our reviews? Are Yelpers a sarcastic bunch? And what kinds of correlations do you see between tips and reviews: could you extract tips from reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = ndf['stars_x']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3b6766a2b743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# apply those models to the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresult_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mresult_bdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mresult_rfdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,RandomForestClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# try other ensemble methods (random forest=, extra tree, adaboost, gradient boosting)\n",
    "dt = DecisionTreeClassifier(random_state=3)\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier(random_state=3))\n",
    "rfdt = RandomForestClassifier(random_state=3)\n",
    "etdt = ExtraTreesClassifier(random_state=3)\n",
    "abdt = AdaBoostClassifier(random_state=3)\n",
    "gbdt = GradientBoostingClassifier(random_state=3)\n",
    "\n",
    "# apply those models to the train set \n",
    "result_dt = dt.fit(x_train,y_train)\n",
    "result_bdt = bdt.fit(x_train,y_train)\n",
    "result_rfdt = rfdt.fit(x_train,y_train)\n",
    "result_etdt = etdt.fit(x_train,y_train)\n",
    "result_abdt = abdt.fit(x_train,y_train)\n",
    "result_gbdt = gbdt.fit(x_train,y_train)\n",
    "\n",
    "# print out the accuracy scores \n",
    "print \"Decision Tree Accuracy Score: \" + str(result_dt.score(x_test,y_test))\n",
    "print \"Bagging Decision Tree Accuracy Score: \" + str(result_bdt.score(x_test,y_test))\n",
    "print \"Random Forest Accuracy Score: \" + str(result_rfdt.score(x_test,y_test))\n",
    "print \"Extra Tree Accuracy Score: \" + str(result_etdt.score(x_test,y_test))\n",
    "print \"Ada Boost Accuracy Score: \" + str(result_abdt.score(x_test,y_test))\n",
    "print \"Gradient Boosting Accuracy Score: \" + str(result_gbdt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changepoints and Events: \n",
    "Can you detect when things change suddenly (i.e. a business coming under new management)? Can you see when a city starts going nuts over cronuts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Graph Mining: \n",
    "Can you figure out who the trend setters are and who found the best waffle joint before waffles were cool? How much influence does my social circle have on my business choices and my ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
